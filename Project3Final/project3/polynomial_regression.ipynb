{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**David Jin**\n",
    "\n",
    "Spring 2023\n",
    "\n",
    "CS 251: Data Analysis and Visualization\n",
    "\n",
    "Project 3: Linear regression\n",
    "\n",
    "Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "import linear_regression\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been creating linear regression fits of form $y =c_0 + c_1x_1 + c_2x_2 + \\ldots$, where $x_i$ are independent variables (columns of $A$) and $c_i$ are corresponding coefficients in $c$. However, this equation only allows us to fit data with a line/plane. This may not be the best choice for all datasets.\n",
    "\n",
    "In this task, you will generalize the linear regression model form to include higher-degree (>1) polynomial terms and explore how this may improve fits to complex data. For example, assume we're doing a simple linear regression with independent variable $x_1$ and dependent variable $y$. A linear regression that fits data with a quadratic shape has the form$$y = c_0 + c_1x_1 + c_2x_1^2$$\n",
    "\n",
    "Complete the following steps to add support for polynomial regression in your `LinearRegression` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Build the polynomial matrix of the independent variable\n",
    "\n",
    "The polynomial matrix contains the independent variable raised to a different power in each column. For example, if $A$ originally has a column vector for the independent variable $\\vec{x_1}$ ($A = [\\vec{x_1}]$) and we wanted to make the above quadratic model, we would append $x_1^2$ ($A = [\\vec{x_1}, \\vec{x_1^2}]$).\n",
    "\n",
    "**TODO:**\n",
    "Implement and test `LinearRegression::make_polynomial_matrix` (*helper method*) that takes care of raising the independent variable samples to different powers.\n",
    "\n",
    "##### Test `make_polynomial_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your polynomial matrix:\n",
      "[[  1   1   1]\n",
      " [  2   4   8]\n",
      " [  3   9  27]\n",
      " [  4  16  64]\n",
      " [  5  25 125]\n",
      " [  6  36 216]\n",
      " [  7  49 343]\n",
      " [  8  64 512]\n",
      " [  9  81 729]]\n",
      "It should look like:\n",
      " \n",
      "[[  1.   1.   1.]\n",
      " [  2.   4.   8.]\n",
      " [  3.   9.  27.]\n",
      " [  4.  16.  64.]\n",
      " [  5.  25. 125.]\n",
      " [  6.  36. 216.]\n",
      " [  7.  49. 343.]\n",
      " [  8.  64. 512.]\n",
      " [  9.  81. 729.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_A = np.r_[1:10].reshape((9, 1))\n",
    "test_p = 3\n",
    "\n",
    "# Test cubic\n",
    "lin_reg = linear_regression.LinearRegression(data.Data())\n",
    "print(f'Your polynomial matrix:\\n{lin_reg.make_polynomial_matrix(test_A, 3)}')\n",
    "\n",
    "true_mat = '''\n",
    "[[  1.   1.   1.]\n",
    " [  2.   4.   8.]\n",
    " [  3.   9.  27.]\n",
    " [  4.  16.  64.]\n",
    " [  5.  25. 125.]\n",
    " [  6.  36. 216.]\n",
    " [  7.  49. 343.]\n",
    " [  8.  64. 512.]\n",
    " [  9.  81. 729.]]\n",
    "'''\n",
    "print('It should look like:\\n', true_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Add support for polynomial regression\n",
    "\n",
    "This can be performed in 3 steps:\n",
    "\n",
    "\n",
    "1. Implement the `LinearRegression::polynomial_regression` method to perform the polynomial regression (*alternate option: you may instead update your `linear_regression` method. If you decide to go this route, add a keyword argument for the polynomial degree with a default value of 1 to preserve compatability with regular linear regression.*).\n",
    "2. Update `LinearRegression::predict`: Run `make_polynomial_matrix` on the \"A\" matrix that enters into the computation $y = Ac$ if `self.p > 1`.\n",
    "3. Add support for plotting polynomials in `LinearRegression::scatter` by generalizing the plotted regression line to a regression polynomial if `self.p > 1`:\n",
    "    - Getting your polynomial \"x\" values: Run `make_polynomial_matrix` on your evenly-spaced line sample points. To get the shapes to work out, you may need to add a trailing singleton dimension to your \"x\" sample points. For example, if you have 1000 \"x\" sample points, make the shape `(1000, 1)` rather than `(1000,)`.\n",
    "    - Getting your polynomial \"y\" values: Use matrix multiplication with your polynomial regression model slopes and/or intercepts.\n",
    "\n",
    "*There is no explicit test code here — visualizing the fit in the next subtask will help you debug!*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Run a polynomial regression\n",
    "\n",
    "In this subtask, you will debug your polynomial regression implementation and experiment fitting some data with it.\n",
    "\n",
    "#### Test: Polynomial regression with linear model ($p = 1$)\n",
    "\n",
    "- In the cell below, fit the `poly_data.csv` dataset using polynomial regression where the polynomial degree $p = 1$.\n",
    "- Use `scatter` to plot the results.\n",
    "- Print out the mean squared error.\n",
    "\n",
    "The plot created by running the below cell should \"look right\" to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.81095284569935\n"
     ]
    }
   ],
   "source": [
    "poly_data = data.Data(\"data/poly_data.csv\")\n",
    "lr = linear_regression.LinearRegression(poly_data)\n",
    "lr.poly_regression(\"X\",\"Y\",1)\n",
    "lr.scatter(\"X\",\"Y\",\"X vs Y\")\n",
    "print(lr.m_sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: polynomial regression with high degree polynomials\n",
    "\n",
    "Repeat the steps from the $p = 1$ test above in the cell below, but this time try $p = 7$. \n",
    "\n",
    "*Your regression fit should not be a line!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.03088073278098\n"
     ]
    }
   ],
   "source": [
    "poly_data = data.Data(\"data/poly_data.csv\")\n",
    "lr = linear_regression.LinearRegression(poly_data)\n",
    "lr.poly_regression(\"X\",\"Y\",7)\n",
    "lr.scatter(\"X\",\"Y\",\"X vs Y\")\n",
    "print(lr.m_sse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Describe the fit compared to `p=1` — is it better or worse? Why? \n",
    "\n",
    "\n",
    "\n",
    "**Question 5:** Describe what happens visually and in terms of the $R^2$ and MSE values as you experiment with the polynomial degree between 1 and 7."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4: The fit for p=7 is better because the MSSE is lower.**\n",
    "\n",
    "**Answer 5: When the P degree increased the R^2 increased while MSSE decreased.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Overfitting\n",
    "\n",
    "In this subtask, you will experiment with how polynomial regression generalize to data not used to fit the regression model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Create fit and validation sets\n",
    "\n",
    "The `poly_data.csv` dataset has 100 samples ($N=100$). In the cell below, split these samples into two separate \"datasets\" and create 2 `Data` objects representing:\n",
    "- The first 50% of samples will be used to fit the regression model (i.e. run linear regression on these samples). We will call this the **fit set** (data used to fit the regression).\n",
    "- The second 50% of samples will be set aside and only used to check how well the fitted regression generalizes to new data. We will call this the **validation set**.\n",
    "\n",
    "The data samples are already shuffled.\n",
    "\n",
    "*Hint: There is a helpful `Data` method for paring down a dataset into a certain range of samples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "X Y\n",
      "- - - - - - - - - - - - - \n",
      "2.147 11.382\n",
      "9.465 1.034\n",
      "4.52 20.251\n",
      "1.974 2.89\n",
      "-3.358 -6.809\n",
      "... first 5 columns of data.\n",
      "-----------------------------\n",
      "X Y\n",
      "- - - - - - - - - - - - - \n",
      "-3.65 -4.658\n",
      "9.69 -6.107\n",
      "-21.986 -17.271\n",
      "-8.694 -2.22\n",
      "-15.536 -25.608\n",
      "... first 5 columns of data.\n"
     ]
    }
   ],
   "source": [
    "poly_data_one = data.Data(\"data/poly_data.csv\")\n",
    "poly_data_two = data.Data(\"data/poly_data.csv\")\n",
    "\n",
    "fit = linear_regression.LinearRegression(poly_data_one)\n",
    "validation = linear_regression.LinearRegression(poly_data_two)\n",
    "\n",
    "\n",
    "fit.data.limit_samples(0, 50)\n",
    "validation.data.limit_samples(50, 101)\n",
    "\n",
    "print(fit.data)\n",
    "print(validation.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the `Data` object storing the fit set should yield:\n",
    "\n",
    "    -------------------------------\n",
    "    data/polydata.csv (50x2)\n",
    "    Headers:\n",
    "    X\tY\n",
    "    Types:\n",
    "    numeric\tnumeric\n",
    "    -------------------------------\n",
    "    Showing first 5/50 rows.\n",
    "    2.147\t11.382\n",
    "    9.465\t1.034\n",
    "    4.52\t20.251\n",
    "    1.974\t2.89\n",
    "    -3.358\t-6.809\n",
    "\n",
    "    -------------------------------\n",
    "\n",
    "Printing the `Data` object storing the validation set should yield:\n",
    "\n",
    "    -------------------------------\n",
    "    data/polydata.csv (50x2)\n",
    "    Headers:\n",
    "    X\tY\n",
    "    Types:\n",
    "    numeric\tnumeric\n",
    "    -------------------------------\n",
    "    Showing first 5/50 rows.\n",
    "    -3.65\t-4.658\n",
    "    9.69\t-6.107\n",
    "    -21.986\t-17.271\n",
    "    -8.694\t-2.22\n",
    "    -15.536\t-25.608\n",
    "\n",
    "    -------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Check fit generalization on validation set\n",
    "\n",
    "Here is the process for checking how well your fitted linear regression model generalizes to the validation data:\n",
    "1. Create `Data` objects for both the fit and validation data sets (*as you have already done*).\n",
    "2. Run linear regression on the fit set.\n",
    "3. Create a new `LinearRegression` object associated with the validation data.\n",
    "4. Copy over the fitted slope and intercept coefficients associated with the fit set to the validation set `LinearRegression` object.\n",
    "5. Create a scatterplot by calling `scatter` to show the validation data and the regression curve that uses the coefficients fitted on the fit dataset (copied over in Step 4).\n",
    "6. Calculate and report fit statistics (e.g. MSE, $R^2$).\n",
    "\n",
    "Before doing this, implement the following methods to help you copy over the fitted slope, intercept and other data from your fit set `LinearRegression` object:\n",
    "\n",
    "- `get_fitted_slope`: return the fitted regression slopes.\n",
    "- `get_fitted_intercept`: return the fitted regression intercept.\n",
    "- `initialize(ind_vars, dep_var, slope, intercept, p)`: set fields based on passed in parameter values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check overfitting with $p = 7$ polynomial regression model\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "1. Fit a polynomial regression model with $p = 7$ on the fit set.\n",
    "2. Create 2 scatter plots:\n",
    "    - Showing the fit set and regression curve fitted to it.\n",
    "    - Showing the validation set and regression curve that uses the fitted coefficients to the **fit set**.\n",
    "3. Compute and print the MSE for both the fit and validation sets.\n",
    "\n",
    "Use the 6 step process above to guide you through the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training: 37.583997851661955\n",
      "MSE validation: 96.14145992141952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.poly_regression(\"X\",\"Y\",7)\n",
    "validation.poly_regression(\"X\",\"Y\",7)\n",
    "validation.initialize(\"X\",\"Y\",fit.get_fitted_slope(),fit.get_fitted_intercept(),7)\n",
    "\n",
    "pred = validation.predict()\n",
    "validation.R2 = validation.r_squared(pred)\n",
    "\n",
    "fit.scatter(\"X\",\"Y\",\"X/Y training\")\n",
    "plt.figure()\n",
    "validation.scatter(\"X\",\"Y\",\"X/Y validation\")\n",
    "\n",
    "\n",
    "print(\"MSE training:\",fit.m_sse)\n",
    "residuals = validation.compute_residuals(pred)\n",
    "m_sse = np.mean( residuals**2 )\n",
    "print(\"MSE validation:\",m_sse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Describe how the fitted coefficients obtained for the fit set generalize to the validation set. Do they do a good or bad job? Why?\n",
    "\n",
    "**Question 7:** Does the generalization improve or worsen for polynomial degrees < 7? Are Back up your observations with numbers (e.g. MSE, $R^2$).\n",
    "\n",
    "**Question 8:** Are there any values/ranges of polynomial degrees that generalize acceptably to the validation set? Why do you think so?\n",
    "\n",
    "**Question 9:** What happens when you increase the polynomial degree above 7, in the range $7-13$? Why do you think this happens? Back up your observations with numbers (e.g. MSE, $R^2$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 6: They did worse so we have an overfit.**\n",
    "\n",
    "**Answer 7: The generalization did improve with lower polynomial base on adjustments.**\n",
    "\n",
    "**Answer 8: The range of 5 to 6 are acceptable.**\n",
    "\n",
    "**Answer 9: When the degree is above 7, the results are improved. When it passed 13, the problems appeared again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "To receive credit for any extension, you must:\n",
    "- Not modify / prevent any code from the core project from working (e.g. make a copy before changing). In other words, **the notebook test code should still work!**\n",
    "- **You must describe what you did and what you found in detail**. This includes a summary of parameter values used in your simulations.\n",
    "- Include (*labeled!*) plots and/or numbers to present your results.\n",
    "- Write up your extensions below or in a separate notebook.\n",
    "\n",
    "**Rule of thumb: one deep, thorough extension is worth more than several quick, shallow extensions!**\n",
    "\n",
    "**Reminder:** Give credit to all sources, including anyone that you consulted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Your own data\n",
    "\n",
    "- Run linear regression on datasets that interest you. Identify your hypotheses about the association between variables and test them out. Make plots and report all relevant metrics fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear regression algorithm comparison\n",
    "\n",
    "- Research and implement other the linear regression solver methods (e.g. normal equations).\n",
    "- Run and compare how well they do on a dataset of your choice.\n",
    "- Research and implement matrix condition number. Find a dataset with a poor matrix condition number and then compare the regression methods. Which does best and why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confidence intervals or other kinds of error bars on linear regression plots\n",
    "\n",
    "- Add the option to plot 95% confidence intervals on the linear regression predictions in your plot functions (e.g. `scatter`). [This website](https://real-statistics.com/regression/confidence-and-prediction-intervals/) should be a helpful reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Overfitting\n",
    "\n",
    "- Run polynomial regression on other datasets. What degree polynomial works well? When do you overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Stepwise linear regression\n",
    "\n",
    "- Implement the stepwise linear regression discussed in class where you add variables to the regression model one-by-one in a greedy fashion: each variable added out of the available ones not already entered in the regression should result in the largest increase in the adjusted $R^2$ value on the validation data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
